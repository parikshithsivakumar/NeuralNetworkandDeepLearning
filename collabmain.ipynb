{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP+P/cijQi0SZRCJH56pYSo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "db847e624aab4ca6b2742b01eabf46b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a0d07663aabd4ea5a4c7e51a198984f7",
              "IPY_MODEL_2edda295881649418dfa0306b9688658",
              "IPY_MODEL_02dbe54bfc1040d3a8184d474d8e0ba8"
            ],
            "layout": "IPY_MODEL_62e8811df151417c887d7235068f5ea6"
          }
        },
        "a0d07663aabd4ea5a4c7e51a198984f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2501c6677a4c404d99b9e43075cd4710",
            "placeholder": "​",
            "style": "IPY_MODEL_9388b93de150436b907620edc108b33f",
            "value": "model.safetensors: 100%"
          }
        },
        "2edda295881649418dfa0306b9688658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c57f8d027fb41c3a02243823df08bc1",
            "max": 349869368,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2998210ea4c34464b496ced43118060c",
            "value": 349869368
          }
        },
        "02dbe54bfc1040d3a8184d474d8e0ba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef9dfa89aa884f21be0ccefd6896a27c",
            "placeholder": "​",
            "style": "IPY_MODEL_ab08290da5fb42689626ebd0a6a67fa1",
            "value": " 350M/350M [00:02&lt;00:00, 192MB/s]"
          }
        },
        "62e8811df151417c887d7235068f5ea6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2501c6677a4c404d99b9e43075cd4710": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9388b93de150436b907620edc108b33f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c57f8d027fb41c3a02243823df08bc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2998210ea4c34464b496ced43118060c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef9dfa89aa884f21be0ccefd6896a27c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab08290da5fb42689626ebd0a6a67fa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parikshithsivakumar/NeuralNetworkandDeepLearning/blob/main/collabmain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-JFDlir72Tl",
        "outputId": "3e47d1d9-2158-466f-ba63-fef8198e70b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m119.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m105.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "has8DlSM8fBC",
        "outputId": "bf0e5d71-0ec9-4f23-9f84-9c05fc29bd3b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Change this to your dataset link if you use another one later\n",
        "!gdown --id 1V2BqH0zGLis1a4BCQlULaYMyw113CTdK\n",
        "\n",
        "# Extract the zip\n",
        "with zipfile.ZipFile(\"archive (2).zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"DatasetFlat\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqVUCR9j89-d",
        "outputId": "3704ce4b-f225-428b-87af-7ecd0bca16d2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1V2BqH0zGLis1a4BCQlULaYMyw113CTdK\n",
            "From (redirected): https://drive.google.com/uc?id=1V2BqH0zGLis1a4BCQlULaYMyw113CTdK&confirm=t&uuid=de1e8a2c-338a-47c4-9aca-047e9c5d1413\n",
            "To: /content/archive (2).zip\n",
            "100% 843M/843M [00:13<00:00, 62.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Recursively delete all `.ipynb_checkpoints` folders\n",
        "for root, dirs, files in os.walk(\"DatasetFlat\"):\n",
        "    for d in dirs:\n",
        "        if d == \".ipynb_checkpoints\":\n",
        "            shutil.rmtree(os.path.join(root, d))\n"
      ],
      "metadata": {
        "id": "q1Ni3SsY-ERG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms, models\n",
        "import os\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "transform_val_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Load the dataset\n",
        "dataset_path = \"/content/DatasetFlat/Minet 5640 Images\"  # Based on extracted folder structure\n",
        "dataset = datasets.ImageFolder(dataset_path, transform=transform_train)\n",
        "class_names = dataset.classes\n",
        "\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = int(0.15 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "train_subset, val_subset, test_subset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "val_subset.dataset.transform = transform_val_test\n",
        "test_subset.dataset.transform = transform_val_test\n",
        "\n",
        "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_subset, batch_size=32)\n",
        "test_loader = DataLoader(test_subset, batch_size=32)\n",
        "\n",
        "# Load ConvNeXt model\n",
        "model = models.convnext_base(weights='IMAGENET1K_V1')\n",
        "model.classifier[2] = nn.Linear(model.classifier[2].in_features, len(class_names))\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "num_epochs = 5\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "best_acc = 0.0\n",
        "\n",
        "os.makedirs(\"saved_models\", exist_ok=True)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    for phase in ['train', 'val']:\n",
        "        model.train() if phase == 'train' else model.eval()\n",
        "        loader = train_loader if phase == 'train' else val_loader\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in tqdm(loader, desc=phase):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                preds = torch.argmax(outputs, 1)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels).item()\n",
        "\n",
        "        epoch_loss = running_loss / len(loader.dataset)\n",
        "        epoch_acc = running_corrects / len(loader.dataset)\n",
        "        print(f\"{phase.capitalize()} Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}\")\n",
        "\n",
        "        if phase == 'val' and epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "# Save best model\n",
        "model.load_state_dict(best_model_wts)\n",
        "torch.save(model.state_dict(), 'saved_models/convnext_best.pth')\n",
        "print(f\"\\n✅ Best ConvNeXt model saved with val accuracy: {best_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOvvXMk29RrP",
        "outputId": "e213d717-6bb2-4a1f-e604-029146502889"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/convnext_base-6075fbad.pth\" to /root/.cache/torch/hub/checkpoints/convnext_base-6075fbad.pth\n",
            "100%|██████████| 338M/338M [00:02<00:00, 161MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/5\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 124/124 [05:01<00:00,  2.43s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.8113, Acc: 0.7352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val: 100%|██████████| 27/27 [00:21<00:00,  1.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.3122, Acc: 0.9078\n",
            "\n",
            "Epoch 2/5\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 124/124 [05:06<00:00,  2.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.2044, Acc: 0.9450\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val: 100%|██████████| 27/27 [00:21<00:00,  1.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.2380, Acc: 0.9314\n",
            "\n",
            "Epoch 3/5\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 124/124 [05:05<00:00,  2.46s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0944, Acc: 0.9767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val: 100%|██████████| 27/27 [00:21<00:00,  1.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.1834, Acc: 0.9374\n",
            "\n",
            "Epoch 4/5\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 124/124 [05:06<00:00,  2.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0718, Acc: 0.9805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val: 100%|██████████| 27/27 [00:21<00:00,  1.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.2089, Acc: 0.9326\n",
            "\n",
            "Epoch 5/5\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train: 100%|██████████| 124/124 [05:07<00:00,  2.48s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.0535, Acc: 0.9856\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val: 100%|██████████| 27/27 [00:21<00:00,  1.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Loss: 0.1717, Acc: 0.9385\n",
            "\n",
            "✅ Best ConvNeXt model saved with val accuracy: 0.9385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# Define test transform\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "dataset_path = \"/content/DatasetFlat/Minet 5640 Images\"\n",
        "dataset = datasets.ImageFolder(dataset_path, transform=transform_test)\n",
        "class_names = dataset.classes\n",
        "\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = int(0.15 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "_, _, test_subset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
        "test_loader = DataLoader(test_subset, batch_size=32, shuffle=False)\n",
        "\n",
        "model = models.convnext_base(weights=None)\n",
        "model.classifier[2] = nn.Linear(model.classifier[2].in_features, len(class_names))\n",
        "model.load_state_dict(torch.load('saved_models/convnext_best.pth', map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Convert to numpy arrays\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = (all_preds == all_labels).mean()\n",
        "print(f\"\\n✅ ConvNeXt Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Classification report (precision, recall, f1-score per class)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93aJQcMb9-Mi",
        "outputId": "bb74fcf1-50a4-4195-cc40-d2414e703aee"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 27/27 [00:23<00:00,  1.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ ConvNeXt Test Accuracy: 0.9705\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     biotite       0.96      0.95      0.96       142\n",
            "     bornite       0.99      0.97      0.98        78\n",
            " chrysocolla       0.95      0.96      0.96        82\n",
            "   malachite       0.98      0.98      0.98       168\n",
            "   muscovite       0.87      0.92      0.89        64\n",
            "      pyrite       0.99      1.00      0.99       154\n",
            "      quartz       0.99      0.97      0.98       159\n",
            "\n",
            "    accuracy                           0.97       847\n",
            "   macro avg       0.96      0.97      0.96       847\n",
            "weighted avg       0.97      0.97      0.97       847\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[135   0   0   0   7   0   0]\n",
            " [  1  76   0   0   1   0   0]\n",
            " [  0   0  79   3   0   0   0]\n",
            " [  0   0   3 165   0   0   0]\n",
            " [  2   1   1   0  59   0   1]\n",
            " [  0   0   0   0   0 154   0]\n",
            " [  2   0   0   0   1   2 154]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import copy\n",
        "import time\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Data transforms for EfficientNet (input size 224x224)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load dataset (adjust your path)\n",
        "full_dataset = datasets.ImageFolder('/content/DatasetFlat/Minet 5640 Images', transform=None)\n",
        "# Split dataset into train/val (80/20 split)\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_subset, val_subset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "# Apply transforms to subsets\n",
        "train_subset.dataset.transform = train_transform\n",
        "val_subset.dataset.transform = val_transform\n",
        "\n",
        "# Data loaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Load EfficientNet-b0 pretrained model\n",
        "model = models.efficientnet_b0(pretrained=True)\n",
        "num_classes = len(full_dataset.classes)\n",
        "\n",
        "# Replace classifier head\n",
        "model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "num_epochs = 5\n",
        "best_acc = 0.0\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    for phase in ['train', 'val']:\n",
        "        if phase == 'train':\n",
        "            model.train()\n",
        "            loader = train_loader\n",
        "        else:\n",
        "            model.eval()\n",
        "            loader = val_loader\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                preds = torch.argmax(outputs, 1)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels).item()\n",
        "\n",
        "        epoch_loss = running_loss / len(loader.dataset)\n",
        "        epoch_acc = running_corrects / len(loader.dataset)\n",
        "        print(f\"{phase.capitalize()} Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}\")\n",
        "\n",
        "        if phase == 'val' and epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "model.load_state_dict(best_model_wts)\n",
        "torch.save(model.state_dict(), 'saved_models/efficientnet_b0_best.pth')\n",
        "print(f\"\\nBest val accuracy: {best_acc:.4f}\")\n",
        "print(\"Model saved as saved_models/efficientnet_b0_best.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpUGryJPEatW",
        "outputId": "89bc7a4e-f695-44e6-c8db-01d5c9528857"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 130MB/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/5\n",
            "Train Loss: 1.1879, Acc: 0.6281\n",
            "Val Loss: 0.5469, Acc: 0.8422\n",
            "\n",
            "Epoch 2/5\n",
            "Train Loss: 0.4551, Acc: 0.8655\n",
            "Val Loss: 0.2936, Acc: 0.9069\n",
            "\n",
            "Epoch 3/5\n",
            "Train Loss: 0.2406, Acc: 0.9309\n",
            "Val Loss: 0.2315, Acc: 0.9255\n",
            "\n",
            "Epoch 4/5\n",
            "Train Loss: 0.1627, Acc: 0.9515\n",
            "Val Loss: 0.2137, Acc: 0.9362\n",
            "\n",
            "Epoch 5/5\n",
            "Train Loss: 0.1069, Acc: 0.9716\n",
            "Val Loss: 0.2072, Acc: 0.9353\n",
            "\n",
            "Best val accuracy: 0.9362\n",
            "Model saved as saved_models/efficientnet_b0_best.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# Define test transform\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "dataset_path = \"/content/DatasetFlat/Minet 5640 Images\"\n",
        "dataset = datasets.ImageFolder(dataset_path, transform=transform_test)\n",
        "class_names = dataset.classes\n",
        "\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = int(0.15 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "_, _, test_subset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
        "test_loader = DataLoader(test_subset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Load EfficientNet-B0 model, change classifier for your num_classes\n",
        "model = models.efficientnet_b0(weights=None)\n",
        "model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(class_names))\n",
        "\n",
        "# Load saved weights\n",
        "model.load_state_dict(torch.load('saved_models/efficientnet_b0_best.pth', map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Convert to numpy arrays\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = (all_preds == all_labels).mean()\n",
        "print(f\"\\n✅ EfficientNet Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Classification report (precision, recall, f1-score per class)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TR98SmVYFmqO",
        "outputId": "d38e4dd3-de02-4538-e938-e4e08caf0292"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 27/27 [00:13<00:00,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ EfficientNet Test Accuracy: 0.9728\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     biotite       0.94      1.00      0.97       168\n",
            "     bornite       0.96      0.89      0.92        61\n",
            " chrysocolla       0.96      0.97      0.97        78\n",
            "   malachite       0.99      0.99      0.99       145\n",
            "   muscovite       0.96      0.85      0.90        54\n",
            "      pyrite       0.99      1.00      0.99       163\n",
            "      quartz       0.99      0.98      0.98       178\n",
            "\n",
            "    accuracy                           0.97       847\n",
            "   macro avg       0.97      0.95      0.96       847\n",
            "weighted avg       0.97      0.97      0.97       847\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[168   0   0   0   0   0   0]\n",
            " [  2  54   1   1   2   1   0]\n",
            " [  0   1  76   1   0   0   0]\n",
            " [  0   1   1 143   0   0   0]\n",
            " [  5   0   1   0  46   0   2]\n",
            " [  0   0   0   0   0 163   0]\n",
            " [  3   0   0   0   0   1 174]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import copy\n",
        "import time\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Data transforms (224x224)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "full_dataset = datasets.ImageFolder('/content/DatasetFlat/Minet 5640 Images', transform=None)\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_subset, val_subset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "# Apply transforms to subsets\n",
        "train_subset.dataset.transform = train_transform\n",
        "val_subset.dataset.transform = val_transform\n",
        "\n",
        "# Data loaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Load DenseNet121 pretrained model\n",
        "model = models.densenet121(pretrained=True)\n",
        "num_classes = len(full_dataset.classes)\n",
        "\n",
        "# Replace classifier\n",
        "model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "best_acc = 0.0\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    for phase in ['train', 'val']:\n",
        "        model.train() if phase == 'train' else model.eval()\n",
        "        loader = train_loader if phase == 'train' else val_loader\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                preds = torch.argmax(outputs, 1)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels).item()\n",
        "\n",
        "        epoch_loss = running_loss / len(loader.dataset)\n",
        "        epoch_acc = running_corrects / len(loader.dataset)\n",
        "        print(f\"{phase.capitalize()} Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}\")\n",
        "\n",
        "        if phase == 'val' and epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "# Save best model\n",
        "model.load_state_dict(best_model_wts)\n",
        "torch.save(model.state_dict(), 'saved_models/densenet121_best.pth')\n",
        "print(f\"\\nBest val accuracy: {best_acc:.4f}\")\n",
        "print(\"Model saved as saved_models/densenet121_best.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raj31VZoHbG7",
        "outputId": "e260c6fe-3ccb-45a3-f3c3-53410b859697"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Epoch 1/10\n",
            "Train Loss: 0.7521, Acc: 0.7640\n",
            "Val Loss: 0.3011, Acc: 0.9220\n",
            "\n",
            "Epoch 2/10\n",
            "Train Loss: 0.2018, Acc: 0.9499\n",
            "Val Loss: 0.2198, Acc: 0.9335\n",
            "\n",
            "Epoch 3/10\n",
            "Train Loss: 0.0903, Acc: 0.9763\n",
            "Val Loss: 0.2100, Acc: 0.9273\n",
            "\n",
            "Epoch 4/10\n",
            "Train Loss: 0.0565, Acc: 0.9860\n",
            "Val Loss: 0.2057, Acc: 0.9424\n",
            "\n",
            "Epoch 5/10\n",
            "Train Loss: 0.0473, Acc: 0.9867\n",
            "Val Loss: 0.2224, Acc: 0.9371\n",
            "\n",
            "Epoch 6/10\n",
            "Train Loss: 0.0396, Acc: 0.9880\n",
            "Val Loss: 0.2124, Acc: 0.9459\n",
            "\n",
            "Epoch 7/10\n",
            "Train Loss: 0.0313, Acc: 0.9887\n",
            "Val Loss: 0.2135, Acc: 0.9424\n",
            "\n",
            "Epoch 8/10\n",
            "Train Loss: 0.0308, Acc: 0.9883\n",
            "Val Loss: 0.2008, Acc: 0.9495\n",
            "\n",
            "Epoch 9/10\n",
            "Train Loss: 0.0312, Acc: 0.9889\n",
            "Val Loss: 0.2233, Acc: 0.9388\n",
            "\n",
            "Epoch 10/10\n",
            "Train Loss: 0.0320, Acc: 0.9860\n",
            "Val Loss: 0.2110, Acc: 0.9468\n",
            "\n",
            "Best val accuracy: 0.9495\n",
            "Model saved as saved_models/densenet121_best.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# Test transforms\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "dataset_path = \"/content/DatasetFlat/Minet 5640 Images\"\n",
        "dataset = datasets.ImageFolder(dataset_path, transform=transform_test)\n",
        "class_names = dataset.classes\n",
        "\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = int(0.15 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "_, _, test_subset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
        "test_loader = DataLoader(test_subset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Load DenseNet-121 and update classifier\n",
        "model = models.densenet121(weights=None)\n",
        "model.classifier = nn.Linear(model.classifier.in_features, len(class_names))\n",
        "\n",
        "# Load saved model weights\n",
        "model.load_state_dict(torch.load('saved_models/densenet121_best.pth', map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "accuracy = (all_preds == all_labels).mean()\n",
        "print(f\"\\n✅ DenseNet-121 Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWiUtuBJKDIm",
        "outputId": "955eafd8-b7d1-465d-cb36-e821ce124e05"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 27/27 [00:17<00:00,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ DenseNet-121 Test Accuracy: 0.9858\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     biotite       0.97      0.98      0.97       133\n",
            "     bornite       0.98      1.00      0.99        64\n",
            " chrysocolla       0.98      1.00      0.99        87\n",
            "   malachite       0.99      0.99      0.99       164\n",
            "   muscovite       1.00      0.88      0.94        50\n",
            "      pyrite       1.00      0.99      1.00       169\n",
            "      quartz       0.98      1.00      0.99       180\n",
            "\n",
            "    accuracy                           0.99       847\n",
            "   macro avg       0.99      0.98      0.98       847\n",
            "weighted avg       0.99      0.99      0.99       847\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[130   1   0   0   0   0   2]\n",
            " [  0  64   0   0   0   0   0]\n",
            " [  0   0  87   0   0   0   0]\n",
            " [  0   0   2 162   0   0   0]\n",
            " [  4   0   0   1  44   0   1]\n",
            " [  0   0   0   0   0 168   1]\n",
            " [  0   0   0   0   0   0 180]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import copy\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Data transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Dataset\n",
        "full_dataset = datasets.ImageFolder('/content/DatasetFlat/Minet 5640 Images', transform=None)\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_subset, val_subset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "train_subset.dataset.transform = train_transform\n",
        "val_subset.dataset.transform = val_transform\n",
        "\n",
        "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_subset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# Load MobileNetV2\n",
        "model = models.mobilenet_v2(pretrained=True)\n",
        "num_classes = len(full_dataset.classes)\n",
        "model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 5\n",
        "best_acc = 0.0\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    for phase in ['train', 'val']:\n",
        "        model.train() if phase == 'train' else model.eval()\n",
        "        loader = train_loader if phase == 'train' else val_loader\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                preds = torch.argmax(outputs, 1)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels).item()\n",
        "\n",
        "        epoch_loss = running_loss / len(loader.dataset)\n",
        "        epoch_acc = running_corrects / len(loader.dataset)\n",
        "        print(f\"{phase.capitalize()} Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}\")\n",
        "\n",
        "        if phase == 'val' and epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "# Save best model\n",
        "model.load_state_dict(best_model_wts)\n",
        "torch.save(model.state_dict(), 'saved_models/mobilenetv2_best.pth')\n",
        "print(f\"\\nBest val accuracy: {best_acc:.4f}\")\n",
        "print(\"Model saved as saved_models/mobilenetv2_best.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "On86rO_ROx54",
        "outputId": "3d438072-2019-4a88-9791-20a6f481410c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 129MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 0.7847, Acc: 0.7471\n",
            "Val Loss: 0.3263, Acc: 0.9087\n",
            "\n",
            "Epoch 2/5\n",
            "Train Loss: 0.2631, Acc: 0.9187\n",
            "Val Loss: 0.2475, Acc: 0.9344\n",
            "\n",
            "Epoch 3/5\n",
            "Train Loss: 0.1352, Acc: 0.9619\n",
            "Val Loss: 0.2233, Acc: 0.9362\n",
            "\n",
            "Epoch 4/5\n",
            "Train Loss: 0.0778, Acc: 0.9809\n",
            "Val Loss: 0.1917, Acc: 0.9406\n",
            "\n",
            "Epoch 5/5\n",
            "Train Loss: 0.0576, Acc: 0.9845\n",
            "Val Loss: 0.2086, Acc: 0.9379\n",
            "\n",
            "Best val accuracy: 0.9406\n",
            "Model saved as saved_models/mobilenetv2_best.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Transforms\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Dataset\n",
        "dataset_path = \"/content/DatasetFlat/Minet 5640 Images\"\n",
        "dataset = datasets.ImageFolder(dataset_path, transform=transform_test)\n",
        "class_names = dataset.classes\n",
        "\n",
        "# Split only for testing\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = int(0.15 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "_, _, test_subset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
        "test_loader = DataLoader(test_subset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Load MobileNetV2\n",
        "model = models.mobilenet_v2(weights=None)\n",
        "model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, len(class_names))\n",
        "model.load_state_dict(torch.load(\"saved_models/mobilenetv2_best.pth\", map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Evaluation loop\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in tqdm(test_loader, desc=\"Evaluating MobileNetV2\"):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Metrics\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "accuracy = (all_preds == all_labels).mean()\n",
        "print(f\"\\n✅ MobileNetV2 Test Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(all_labels, all_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZV0ZJdCFPqRh",
        "outputId": "c89c8f72-13c2-47c6-965c-e84c4c54d21d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating MobileNetV2: 100%|██████████| 27/27 [00:15<00:00,  1.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ MobileNetV2 Test Accuracy: 0.9764\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     biotite       0.96      0.98      0.97       164\n",
            "     bornite       0.95      0.98      0.97        61\n",
            " chrysocolla       1.00      0.96      0.98        92\n",
            "   malachite       0.97      0.98      0.97       156\n",
            "   muscovite       0.98      0.91      0.95        47\n",
            "      pyrite       0.98      0.99      0.99       157\n",
            "      quartz       0.99      0.98      0.99       170\n",
            "\n",
            "    accuracy                           0.98       847\n",
            "   macro avg       0.98      0.97      0.97       847\n",
            "weighted avg       0.98      0.98      0.98       847\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[160   2   0   0   0   0   2]\n",
            " [  1  60   0   0   0   0   0]\n",
            " [  0   0  88   4   0   0   0]\n",
            " [  0   0   0 153   0   3   0]\n",
            " [  3   1   0   0  43   0   0]\n",
            " [  0   0   0   1   0 156   0]\n",
            " [  2   0   0   0   1   0 167]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import copy\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load dataset and split\n",
        "full_dataset = datasets.ImageFolder('/content/DatasetFlat/Minet 5640 Images', transform=None)\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_subset, val_subset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "# Apply transforms\n",
        "train_subset.dataset.transform = train_transform\n",
        "val_subset.dataset.transform = val_transform\n",
        "\n",
        "# Dataloaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Load pretrained MobileNetV3-Large\n",
        "model = models.mobilenet_v3_large(weights=models.MobileNet_V3_Large_Weights.DEFAULT)\n",
        "num_classes = len(full_dataset.classes)\n",
        "model.classifier[3] = nn.Linear(model.classifier[3].in_features, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 5\n",
        "best_acc = 0.0\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    for phase in ['train', 'val']:\n",
        "        model.train() if phase == 'train' else model.eval()\n",
        "        loader = train_loader if phase == 'train' else val_loader\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                preds = torch.argmax(outputs, 1)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels).item()\n",
        "\n",
        "        epoch_loss = running_loss / len(loader.dataset)\n",
        "        epoch_acc = running_corrects / len(loader.dataset)\n",
        "        print(f\"{phase.capitalize()} Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}\")\n",
        "\n",
        "        if phase == 'val' and epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "# Save best model\n",
        "model.load_state_dict(best_model_wts)\n",
        "torch.save(model.state_dict(), 'saved_models/mobilenetv3_large_best.pth')\n",
        "print(f\"\\n✅ Best val accuracy: {best_acc:.4f}\")\n",
        "print(\"📦 Model saved to: saved_models/mobilenetv3_large_best.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-QwdeVkQfwd",
        "outputId": "c7d17b20-b40f-4db9-86d2-0cddfd652c22"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_large-5c1a4163.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_large-5c1a4163.pth\n",
            "100%|██████████| 21.1M/21.1M [00:00<00:00, 55.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/5\n",
            "Train Loss: 0.9685, Acc: 0.6797\n",
            "Val Loss: 0.4336, Acc: 0.8546\n",
            "\n",
            "Epoch 2/5\n",
            "Train Loss: 0.3003, Acc: 0.9056\n",
            "Val Loss: 0.2697, Acc: 0.9211\n",
            "\n",
            "Epoch 3/5\n",
            "Train Loss: 0.1414, Acc: 0.9577\n",
            "Val Loss: 0.1904, Acc: 0.9406\n",
            "\n",
            "Epoch 4/5\n",
            "Train Loss: 0.0828, Acc: 0.9752\n",
            "Val Loss: 0.1819, Acc: 0.9424\n",
            "\n",
            "Epoch 5/5\n",
            "Train Loss: 0.0592, Acc: 0.9803\n",
            "Val Loss: 0.1891, Acc: 0.9459\n",
            "\n",
            "✅ Best val accuracy: 0.9459\n",
            "📦 Model saved to: saved_models/mobilenetv3_large_best.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Transforms for evaluation\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "dataset_path = \"/content/DatasetFlat/Minet 5640 Images\"\n",
        "dataset = datasets.ImageFolder(dataset_path, transform=transform_test)\n",
        "class_names = dataset.classes\n",
        "\n",
        "# Split dataset into train/val/test (same method)\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = int(0.15 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "_, _, test_subset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
        "test_loader = DataLoader(test_subset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Load MobileNetV3-Large model\n",
        "model = models.mobilenet_v3_large(weights=None)\n",
        "model.classifier[3] = torch.nn.Linear(model.classifier[3].in_features, len(class_names))\n",
        "model.load_state_dict(torch.load('saved_models/mobilenetv3_large_best.pth', map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Inference loop\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in tqdm(test_loader, desc=\"Evaluating MobileNetV3-Large\"):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Convert to numpy arrays\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = (all_preds == all_labels).mean()\n",
        "print(f\"\\n✅ MobileNetV3-Large Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Classification report\n",
        "print(\"\\n📊 Classification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
        "\n",
        "# Confusion matrix\n",
        "print(\"\\n🧩 Confusion Matrix:\")\n",
        "print(confusion_matrix(all_labels, all_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JP5_DQySi3x",
        "outputId": "feade1a8-06f7-4c38-8adb-059c193d350d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating MobileNetV3-Large: 100%|██████████| 27/27 [00:17<00:00,  1.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ MobileNetV3-Large Test Accuracy: 0.9752\n",
            "\n",
            "📊 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     biotite       0.98      0.99      0.98       165\n",
            "     bornite       0.98      0.93      0.96        60\n",
            " chrysocolla       0.95      1.00      0.98        79\n",
            "   malachite       1.00      0.97      0.99       157\n",
            "   muscovite       0.97      0.90      0.93        68\n",
            "      pyrite       0.98      0.99      0.98       155\n",
            "      quartz       0.96      0.99      0.97       163\n",
            "\n",
            "    accuracy                           0.98       847\n",
            "   macro avg       0.97      0.97      0.97       847\n",
            "weighted avg       0.98      0.98      0.98       847\n",
            "\n",
            "\n",
            "🧩 Confusion Matrix:\n",
            "[[163   0   0   0   1   1   0]\n",
            " [  0  56   0   0   1   1   2]\n",
            " [  0   0  79   0   0   0   0]\n",
            " [  0   0   4 153   0   0   0]\n",
            " [  4   0   0   0  61   0   3]\n",
            " [  0   0   0   0   0 153   2]\n",
            " [  0   1   0   0   0   1 161]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models import swin_t\n",
        "import copy\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Data transforms (Swin Transformer typically uses 224x224 input)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load dataset and split\n",
        "dataset_path = '/content/DatasetFlat/Minet 5640 Images'\n",
        "full_dataset = datasets.ImageFolder(dataset_path, transform=None)\n",
        "\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_subset, val_subset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "# Apply transforms to subsets\n",
        "train_subset.dataset.transform = train_transform\n",
        "val_subset.dataset.transform = val_transform\n",
        "\n",
        "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_subset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# Load pretrained Swin Transformer small model\n",
        "model = swin_t(weights='DEFAULT')  # pretrained weights\n",
        "num_classes = len(full_dataset.classes)\n",
        "\n",
        "# Replace head for classification\n",
        "model.head = nn.Linear(model.head.in_features, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "num_epochs = 5\n",
        "best_acc = 0.0\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    for phase in ['train', 'val']:\n",
        "        model.train() if phase == 'train' else model.eval()\n",
        "        loader = train_loader if phase == 'train' else val_loader\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels).item()\n",
        "\n",
        "        epoch_loss = running_loss / len(loader.dataset)\n",
        "        epoch_acc = running_corrects / len(loader.dataset)\n",
        "\n",
        "        print(f\"{phase.capitalize()} Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}\")\n",
        "\n",
        "        if phase == 'val' and epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "model.load_state_dict(best_model_wts)\n",
        "torch.save(model.state_dict(), 'saved_models/swin_t_best.pth')\n",
        "print(f\"\\nBest val accuracy: {best_acc:.4f}\")\n",
        "print(\"Model saved as saved_models/swin_t_best.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzIUSy0tUOkZ",
        "outputId": "9db54157-75f8-4445-a232-ec9197aab764"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/swin_t-704ceda3.pth\" to /root/.cache/torch/hub/checkpoints/swin_t-704ceda3.pth\n",
            "100%|██████████| 108M/108M [00:01<00:00, 103MB/s]  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/5\n",
            "Train Loss: 0.7217, Acc: 0.7575\n",
            "Val Loss: 0.2989, Acc: 0.9007\n",
            "\n",
            "Epoch 2/5\n",
            "Train Loss: 0.2511, Acc: 0.9238\n",
            "Val Loss: 0.2353, Acc: 0.9309\n",
            "\n",
            "Epoch 3/5\n",
            "Train Loss: 0.1357, Acc: 0.9592\n",
            "Val Loss: 0.2106, Acc: 0.9406\n",
            "\n",
            "Epoch 4/5\n",
            "Train Loss: 0.0994, Acc: 0.9714\n",
            "Val Loss: 0.1889, Acc: 0.9459\n",
            "\n",
            "Epoch 5/5\n",
            "Train Loss: 0.0795, Acc: 0.9738\n",
            "Val Loss: 0.1877, Acc: 0.9486\n",
            "\n",
            "Best val accuracy: 0.9486\n",
            "Model saved as saved_models/swin_t_best.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Test transform (same as validation)\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "dataset_path = '/content/DatasetFlat/Minet 5640 Images'\n",
        "dataset = datasets.ImageFolder(dataset_path, transform=transform_test)\n",
        "\n",
        "# Split dataset (train/val/test split assumed, here just for test)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = int(0.1 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "_, _, test_subset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
        "test_loader = DataLoader(test_subset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Load model architecture\n",
        "from torchvision.models import swin_t\n",
        "model = swin_t(weights=None)\n",
        "num_classes = len(dataset.classes)\n",
        "model.head = nn.Linear(model.head.in_features, num_classes)\n",
        "model.load_state_dict(torch.load('saved_models/swin_t_best.pth', map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "accuracy = (all_preds == all_labels).mean()\n",
        "print(f\"\\n✅ Swin Transformer Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=dataset.classes))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(all_labels, all_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKDZpCj6U4sJ",
        "outputId": "85c812ea-ed0f-40a3-8962-e6ad27d9b901"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 18/18 [00:10<00:00,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Swin Transformer Test Accuracy: 0.9823\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     biotite       0.96      0.98      0.97       112\n",
            "     bornite       0.98      0.98      0.98        42\n",
            " chrysocolla       0.98      0.94      0.96        53\n",
            "   malachite       0.98      0.99      0.99       103\n",
            "   muscovite       0.96      0.93      0.95        29\n",
            "      pyrite       1.00      1.00      1.00       120\n",
            "      quartz       1.00      0.99      1.00       105\n",
            "\n",
            "    accuracy                           0.98       564\n",
            "   macro avg       0.98      0.97      0.98       564\n",
            "weighted avg       0.98      0.98      0.98       564\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[110   1   0   0   1   0   0]\n",
            " [  1  41   0   0   0   0   0]\n",
            " [  1   0  50   2   0   0   0]\n",
            " [  0   0   1 102   0   0   0]\n",
            " [  2   0   0   0  27   0   0]\n",
            " [  0   0   0   0   0 120   0]\n",
            " [  1   0   0   0   0   0 104]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import copy\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Data transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "full_dataset = datasets.ImageFolder('/content/DatasetFlat/Minet 5640 Images', transform=None)\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_subset, val_subset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "train_subset.dataset.transform = train_transform\n",
        "val_subset.dataset.transform = val_transform\n",
        "\n",
        "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_subset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# Load RegNetY_400MF pretrained model\n",
        "model = models.regnet_y_400mf(pretrained=True)\n",
        "num_classes = len(full_dataset.classes)\n",
        "\n",
        "# Replace classifier head\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "num_epochs = 10\n",
        "best_acc = 0.0\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    for phase in ['train', 'val']:\n",
        "        if phase == 'train':\n",
        "            model.train()\n",
        "            loader = train_loader\n",
        "        else:\n",
        "            model.eval()\n",
        "            loader = val_loader\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                preds = torch.argmax(outputs, 1)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels).item()\n",
        "\n",
        "        epoch_loss = running_loss / len(loader.dataset)\n",
        "        epoch_acc = running_corrects / len(loader.dataset)\n",
        "        print(f\"{phase.capitalize()} Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}\")\n",
        "\n",
        "        if phase == 'val' and epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "model.load_state_dict(best_model_wts)\n",
        "torch.save(model.state_dict(), 'saved_models/regnet_y_400mf_best.pth')\n",
        "print(f\"\\nBest val accuracy: {best_acc:.4f}\")\n",
        "print(\"Model saved as saved_models/regnet_y_400mf_best.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpjIvYLTWh8X",
        "outputId": "5913e5ce-b580-42c3-e928-91b2f535f997"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Epoch 1/10\n",
            "Train Loss: 0.8924, Acc: 0.7165\n",
            "Val Loss: 0.3845, Acc: 0.8954\n",
            "\n",
            "Epoch 2/10\n",
            "Train Loss: 0.2589, Acc: 0.9289\n",
            "Val Loss: 0.2521, Acc: 0.9238\n",
            "\n",
            "Epoch 3/10\n",
            "Train Loss: 0.1257, Acc: 0.9665\n",
            "Val Loss: 0.2287, Acc: 0.9317\n",
            "\n",
            "Epoch 4/10\n",
            "Train Loss: 0.0729, Acc: 0.9796\n",
            "Val Loss: 0.2350, Acc: 0.9282\n",
            "\n",
            "Epoch 5/10\n",
            "Train Loss: 0.0590, Acc: 0.9829\n",
            "Val Loss: 0.2393, Acc: 0.9291\n",
            "\n",
            "Epoch 6/10\n",
            "Train Loss: 0.0477, Acc: 0.9836\n",
            "Val Loss: 0.2288, Acc: 0.9353\n",
            "\n",
            "Epoch 7/10\n",
            "Train Loss: 0.0416, Acc: 0.9867\n",
            "Val Loss: 0.2346, Acc: 0.9362\n",
            "\n",
            "Epoch 8/10\n",
            "Train Loss: 0.0400, Acc: 0.9858\n",
            "Val Loss: 0.2356, Acc: 0.9353\n",
            "\n",
            "Epoch 9/10\n",
            "Train Loss: 0.0368, Acc: 0.9849\n",
            "Val Loss: 0.2310, Acc: 0.9362\n",
            "\n",
            "Epoch 10/10\n",
            "Train Loss: 0.0384, Acc: 0.9858\n",
            "Val Loss: 0.2366, Acc: 0.9371\n",
            "\n",
            "Best val accuracy: 0.9371\n",
            "Model saved as saved_models/regnet_y_400mf_best.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# Define test transform\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "dataset_path = \"/content/DatasetFlat/Minet 5640 Images\"\n",
        "dataset = datasets.ImageFolder(dataset_path, transform=transform_test)\n",
        "class_names = dataset.classes\n",
        "\n",
        "# Split into test subset only\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = int(0.15 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "_, _, test_subset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
        "test_loader = DataLoader(test_subset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Load RegNetY-400MF model\n",
        "model = models.regnet_y_400mf(weights=None)\n",
        "model.fc = torch.nn.Linear(model.fc.in_features, len(class_names))\n",
        "model.load_state_dict(torch.load('/content/saved_models/regnet_y_400mf_best.pth', map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Evaluation\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in tqdm(test_loader, desc=\"Evaluating RegNet\"):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Metrics\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "accuracy = (all_preds == all_labels).mean()\n",
        "print(f\"\\n✅ RegNet Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(all_labels, all_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c11dYGAYYexj",
        "outputId": "0dd794ab-bbab-4ef9-a863-65c88d663a2b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating RegNet: 100%|██████████| 27/27 [00:16<00:00,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ RegNet Test Accuracy: 0.9799\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     biotite       0.97      0.99      0.98       152\n",
            "     bornite       0.97      0.98      0.98        60\n",
            " chrysocolla       0.99      0.94      0.96        85\n",
            "   malachite       0.97      0.99      0.98       145\n",
            "   muscovite       0.96      0.93      0.95        59\n",
            "      pyrite       1.00      0.99      0.99       168\n",
            "      quartz       0.98      0.99      0.99       178\n",
            "\n",
            "    accuracy                           0.98       847\n",
            "   macro avg       0.98      0.97      0.98       847\n",
            "weighted avg       0.98      0.98      0.98       847\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[150   1   0   0   1   0   0]\n",
            " [  1  59   0   0   0   0   0]\n",
            " [  0   1  80   4   0   0   0]\n",
            " [  0   0   1 143   1   0   0]\n",
            " [  2   0   0   0  55   0   2]\n",
            " [  0   0   0   0   0 166   2]\n",
            " [  1   0   0   0   0   0 177]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import copy\n",
        "import time\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Data transforms for ViT (input size 224x224)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "dataset_path = '/content/DatasetFlat/Minet 5640 Images'\n",
        "full_dataset = datasets.ImageFolder(dataset_path, transform=None)\n",
        "\n",
        "# Split dataset into train/val\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_subset, val_subset = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "# Apply transforms\n",
        "train_subset.dataset.transform = train_transform\n",
        "val_subset.dataset.transform = val_transform\n",
        "\n",
        "# Data loaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Load ViT model\n",
        "model = models.vit_b_16(pretrained=True)\n",
        "num_classes = len(full_dataset.classes)\n",
        "model.heads.head = nn.Linear(model.heads.head.in_features, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss, optimizer, scheduler\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "best_acc = 0.0\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "    for phase in ['train', 'val']:\n",
        "        model.train() if phase == 'train' else model.eval()\n",
        "        loader = train_loader if phase == 'train' else val_loader\n",
        "\n",
        "        running_loss, running_corrects = 0.0, 0\n",
        "\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                preds = torch.argmax(outputs, 1)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels).item()\n",
        "\n",
        "        epoch_loss = running_loss / len(loader.dataset)\n",
        "        epoch_acc = running_corrects / len(loader.dataset)\n",
        "        print(f\"{phase.capitalize()} Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}\")\n",
        "\n",
        "        if phase == 'val' and epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "# Save best model\n",
        "model.load_state_dict(best_model_wts)\n",
        "torch.save(model.state_dict(), 'saved_models/vit_best.pth')\n",
        "print(f\"\\n✅ Best validation accuracy: {best_acc:.4f}\")\n",
        "print(\"📦 Model saved to saved_models/vit_best.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPx2pj2IY6Yh",
        "outputId": "8f9dac20-0158-47d7-bcaa-55a6f3358d71"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /root/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n",
            "100%|██████████| 330M/330M [00:02<00:00, 155MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10\n",
            "Train Loss: 0.6543, Acc: 0.7857\n",
            "Val Loss: 0.3488, Acc: 0.8821\n",
            "\n",
            "Epoch 2/10\n",
            "Train Loss: 0.1637, Acc: 0.9512\n",
            "Val Loss: 0.3649, Acc: 0.8945\n",
            "\n",
            "Epoch 3/10\n",
            "Train Loss: 0.1034, Acc: 0.9681\n",
            "Val Loss: 0.2803, Acc: 0.9140\n",
            "\n",
            "Epoch 4/10\n",
            "Train Loss: 0.0777, Acc: 0.9750\n",
            "Val Loss: 0.3208, Acc: 0.9087\n",
            "\n",
            "Epoch 5/10\n",
            "Train Loss: 0.0692, Acc: 0.9785\n",
            "Val Loss: 0.3852, Acc: 0.8954\n",
            "\n",
            "Epoch 6/10\n",
            "Train Loss: 0.0349, Acc: 0.9852\n",
            "Val Loss: 0.3105, Acc: 0.9255\n",
            "\n",
            "Epoch 7/10\n",
            "Train Loss: 0.0277, Acc: 0.9869\n",
            "Val Loss: 0.3179, Acc: 0.9229\n",
            "\n",
            "Epoch 8/10\n",
            "Train Loss: 0.0256, Acc: 0.9885\n",
            "Val Loss: 0.3069, Acc: 0.9273\n",
            "\n",
            "Epoch 9/10\n",
            "Train Loss: 0.0244, Acc: 0.9885\n",
            "Val Loss: 0.3086, Acc: 0.9291\n",
            "\n",
            "Epoch 10/10\n",
            "Train Loss: 0.0246, Acc: 0.9883\n",
            "Val Loss: 0.3326, Acc: 0.9238\n",
            "\n",
            "✅ Best validation accuracy: 0.9291\n",
            "📦 Model saved to saved_models/vit_best.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# Define test transform\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Load dataset and class names\n",
        "dataset_path = \"/content/DatasetFlat/Minet 5640 Images\"\n",
        "dataset = datasets.ImageFolder(dataset_path, transform=transform_test)\n",
        "class_names = dataset.classes\n",
        "\n",
        "# Split and create test set\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = int(0.15 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "_, _, test_subset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
        "test_loader = DataLoader(test_subset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Load the ViT model\n",
        "model = models.vit_b_16(weights=None)\n",
        "model.heads.head = torch.nn.Linear(model.heads.head.in_features, len(class_names))\n",
        "model.load_state_dict(torch.load('saved_models/vit_best.pth', map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Run predictions\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in tqdm(test_loader, desc=\"Evaluating ViT\"):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Accuracy\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "accuracy = (all_preds == all_labels).mean()\n",
        "print(f\"\\n✅ ViT Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
        "\n",
        "# Confusion matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(all_labels, all_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQRPEvz1bB6G",
        "outputId": "488d8854-7af7-4a57-fbfc-43044daf1ead"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating ViT: 100%|██████████| 27/27 [00:24<00:00,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ ViT Test Accuracy: 0.9740\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     biotite       0.94      0.99      0.96       161\n",
            "     bornite       0.98      0.97      0.98        66\n",
            " chrysocolla       1.00      0.99      0.99        82\n",
            "   malachite       1.00      1.00      1.00       133\n",
            "   muscovite       0.96      0.89      0.93        57\n",
            "      pyrite       0.99      0.98      0.98       166\n",
            "      quartz       0.97      0.96      0.96       182\n",
            "\n",
            "    accuracy                           0.97       847\n",
            "   macro avg       0.98      0.97      0.97       847\n",
            "weighted avg       0.97      0.97      0.97       847\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[159   1   0   0   1   0   0]\n",
            " [  1  64   0   0   0   0   1]\n",
            " [  0   0  81   0   0   0   1]\n",
            " [  0   0   0 133   0   0   0]\n",
            " [  5   0   0   0  51   0   1]\n",
            " [  1   0   0   0   0 162   3]\n",
            " [  4   0   0   0   1   2 175]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import timm\n",
        "import copy\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# Transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5],\n",
        "                         [0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5],\n",
        "                         [0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# Dataset\n",
        "dataset_path = '/content/DatasetFlat/Minet 5640 Images'\n",
        "full_dataset = datasets.ImageFolder(dataset_path, transform=None)\n",
        "num_classes = len(full_dataset.classes)\n",
        "\n",
        "# Split\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
        "train_dataset.dataset.transform = train_transform\n",
        "val_dataset.dataset.transform = val_transform\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# Load BEiT from timm\n",
        "model = timm.create_model(\"beit_base_patch16_224\", pretrained=True)\n",
        "model.head = nn.Linear(model.head.in_features, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n",
        "\n",
        "# Training Loop\n",
        "best_acc = 0.0\n",
        "best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "for epoch in range(5):\n",
        "    print(f\"\\nEpoch {epoch+1}/5\")\n",
        "    for phase in ['train', 'val']:\n",
        "        model.train() if phase == 'train' else model.eval()\n",
        "        loader = train_loader if phase == 'train' else val_loader\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                preds = outputs.argmax(dim=1)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels).item()\n",
        "\n",
        "        epoch_loss = running_loss / len(loader.dataset)\n",
        "        epoch_acc = running_corrects / len(loader.dataset)\n",
        "        print(f\"{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
        "\n",
        "        if phase == 'val' and epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "# Save best model\n",
        "model.load_state_dict(best_model_wts)\n",
        "torch.save(model.state_dict(), 'saved_models/beit_best.pth')\n",
        "print(f\"\\n✅ BEiT Best Val Accuracy: {best_acc:.4f}\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572,
          "referenced_widgets": [
            "db847e624aab4ca6b2742b01eabf46b0",
            "a0d07663aabd4ea5a4c7e51a198984f7",
            "2edda295881649418dfa0306b9688658",
            "02dbe54bfc1040d3a8184d474d8e0ba8",
            "62e8811df151417c887d7235068f5ea6",
            "2501c6677a4c404d99b9e43075cd4710",
            "9388b93de150436b907620edc108b33f",
            "3c57f8d027fb41c3a02243823df08bc1",
            "2998210ea4c34464b496ced43118060c",
            "ef9dfa89aa884f21be0ccefd6896a27c",
            "ab08290da5fb42689626ebd0a6a67fa1"
          ]
        },
        "id": "hULQC3zJfB8d",
        "outputId": "f2837803-a51d-4041-de5b-5a84a86f5707"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/350M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "db847e624aab4ca6b2742b01eabf46b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/5\n",
            "Train Loss: 0.6464 Acc: 0.7934\n",
            "Val Loss: 0.2349 Acc: 0.9353\n",
            "\n",
            "Epoch 2/5\n",
            "Train Loss: 0.1164 Acc: 0.9641\n",
            "Val Loss: 0.1852 Acc: 0.9433\n",
            "\n",
            "Epoch 3/5\n",
            "Train Loss: 0.0520 Acc: 0.9852\n",
            "Val Loss: 0.1606 Acc: 0.9477\n",
            "\n",
            "Epoch 4/5\n",
            "Train Loss: 0.0324 Acc: 0.9891\n",
            "Val Loss: 0.1485 Acc: 0.9548\n",
            "\n",
            "Epoch 5/5\n",
            "Train Loss: 0.0274 Acc: 0.9887\n",
            "Val Loss: 0.1489 Acc: 0.9548\n",
            "\n",
            "✅ BEiT Best Val Accuracy: 0.9548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import timm\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# Dataset and transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "dataset_path = \"/content/DatasetFlat/Minet 5640 Images\"\n",
        "full_dataset = datasets.ImageFolder(dataset_path, transform=transform)\n",
        "class_names = full_dataset.classes\n",
        "\n",
        "# Split dataset\n",
        "train_size = int(0.7 * len(full_dataset))\n",
        "val_size = int(0.15 * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size - val_size\n",
        "_, _, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Load BEiT model from timm\n",
        "model = timm.create_model('beit_base_patch16_224', pretrained=False, num_classes=len(class_names))\n",
        "model.load_state_dict(torch.load('saved_models/beit_best.pth', map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Evaluation loop\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = (all_preds == all_labels).mean()\n",
        "print(f\"\\n✅ BEiT Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
        "\n",
        "# Confusion matrix\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(all_labels, all_preds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I0HFKU9lfed",
        "outputId": "128ee6bc-5953-4bb3-bb69-85a1d60aa16c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|██████████| 27/27 [00:24<00:00,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ BEiT Test Accuracy: 0.3589\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     biotite       0.36      0.36      0.36       158\n",
            "     bornite       0.31      0.14      0.19        65\n",
            " chrysocolla       0.39      0.20      0.26        90\n",
            "   malachite       0.57      0.15      0.24       135\n",
            "   muscovite       0.10      0.16      0.13        49\n",
            "      pyrite       0.44      0.50      0.47       157\n",
            "      quartz       0.35      0.59      0.44       193\n",
            "\n",
            "    accuracy                           0.36       847\n",
            "   macro avg       0.36      0.30      0.30       847\n",
            "weighted avg       0.39      0.36      0.34       847\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 57   1   3   0   8  32  57]\n",
            " [ 17   9   2   0   8  11  18]\n",
            " [ 19   2  18   6  16   9  20]\n",
            " [  7   5  22  20  13   9  59]\n",
            " [  9   1   0   2   8  13  16]\n",
            " [ 28   0   0   3   8  79  39]\n",
            " [ 21  11   1   4  17  26 113]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import pandas as pd\n",
        "import timm  # For BEiT model loading\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"🔧 Device:\", device)\n",
        "\n",
        "# Test data transform\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load dataset and create test split\n",
        "dataset_path = \"/content/DatasetFlat/Minet 5640 Images\"\n",
        "dataset = datasets.ImageFolder(dataset_path, transform=transform_test)\n",
        "class_names = dataset.classes\n",
        "\n",
        "train_size = int(0.7 * len(dataset))\n",
        "val_size = int(0.15 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "_, _, test_subset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
        "test_loader = DataLoader(test_subset, batch_size=32, shuffle=False)\n",
        "\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# Mapping model keys to their model loader name in torchvision or 'timm' for beit\n",
        "model_files = {\n",
        "    \"beit\": \"beit_best.pth\",\n",
        "    \"convnext\": \"convnext_best.pth\",\n",
        "    \"densenet121\": \"densenet121_best.pth\",\n",
        "    \"efficientnet_b0\": \"efficientnet_bo_best.pth\",\n",
        "    \"mobilenetv2\": \"mobilenetv2_best.pth\",\n",
        "    \"mobilenetv3_large\": \"mobilenetv3_large_best.pth\",\n",
        "    \"regnet_y_400mf\": \"regnet_y_400mf_best.pth\",\n",
        "    \"swin_t\": \"swin_t_best.pth\",\n",
        "    \"vit\": \"vit_best.pth\"\n",
        "}\n",
        "\n",
        "# Classifier layer info: (path to classifier layer, input features)\n",
        "classifier_layers = {\n",
        "    \"beit\": (\"head\", 768),\n",
        "    \"convnext\": (\"classifier[2]\", 1024),\n",
        "    \"densenet121\": (\"classifier\", 1024),\n",
        "    \"efficientnet_b0\": (\"classifier[1]\", 1280),\n",
        "    \"mobilenetv2\": (\"classifier[1]\", 1280),\n",
        "    \"mobilenetv3_large\": (\"classifier[3]\", 1280),\n",
        "    \"regnet_y_400mf\": (\"fc\", 440),\n",
        "    \"swin_t\": (\"head\", 768),\n",
        "    \"vit\": (\"heads.head\", 768),\n",
        "}\n",
        "\n",
        "# Helper to set the classifier layer safely\n",
        "def set_model_head(model, head_path, in_features, num_classes):\n",
        "    attrs = re.split(r'\\.(?![^\\[]*\\])', head_path)  # Split on '.' but ignore those inside brackets\n",
        "    current = model\n",
        "    for i, attr in enumerate(attrs[:-1]):\n",
        "        if '[' in attr:\n",
        "            # e.g. classifier[2]\n",
        "            name, idx = re.match(r'(\\w+)\\[(\\d+)\\]', attr).groups()\n",
        "            current = getattr(current, name)[int(idx)]\n",
        "        else:\n",
        "            current = getattr(current, attr)\n",
        "\n",
        "    last = attrs[-1]\n",
        "    if '[' in last:\n",
        "        name, idx = re.match(r'(\\w+)\\[(\\d+)\\]', last).groups()\n",
        "        module = getattr(current, name)\n",
        "        module[int(idx)] = nn.Linear(in_features, num_classes)\n",
        "    else:\n",
        "        setattr(current, last, nn.Linear(in_features, num_classes))\n",
        "\n",
        "results = []\n",
        "\n",
        "for model_key, pth_file in model_files.items():\n",
        "    print(f\"\\n🔍 Evaluating {model_key}\")\n",
        "\n",
        "    # Load model\n",
        "    if model_key == \"beit\":\n",
        "        model = timm.create_model(\"beit_base_patch16_224\", pretrained=False, num_classes=num_classes)\n",
        "    else:\n",
        "        # For torchvision model names that differ slightly, fix here if needed\n",
        "        torch_model_name = model_key\n",
        "        if model_key == \"efficientnet_b0\":\n",
        "            torch_model_name = \"efficientnet_b0\"\n",
        "        model = getattr(models, torch_model_name)(weights=None)\n",
        "\n",
        "    # Set classifier head\n",
        "    head_path, in_features = classifier_layers[model_key]\n",
        "    set_model_head(model, head_path, in_features, num_classes)\n",
        "\n",
        "    # Load weights\n",
        "    model.load_state_dict(torch.load(f\"saved_models/{pth_file}\", map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in tqdm(test_loader, desc=model_key):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_labels = np.array(all_labels)\n",
        "    acc = (all_preds == all_labels).mean()\n",
        "    print(f\"\\n✅ {model_key} Accuracy: {acc:.4f}\")\n",
        "\n",
        "    report = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True)\n",
        "    # You can save precision, recall, f1-score for 'macro avg' or 'weighted avg'\n",
        "    macro_f1 = report['macro avg']['f1-score']\n",
        "    weighted_f1 = report['weighted avg']['f1-score']\n",
        "\n",
        "    results.append({\n",
        "        \"Model\": model_key,\n",
        "        \"Accuracy\": acc,\n",
        "        \"Macro F1\": macro_f1,\n",
        "        \"Weighted F1\": weighted_f1\n",
        "    })\n",
        "\n",
        "# Display summary table\n",
        "df_results = pd.DataFrame(results)\n",
        "print(\"\\n\\n📋 Summary of all models:\")\n",
        "print(df_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "fUYCrmfXlzRz",
        "outputId": "ae7b8047-75cd-4318-88ab-c36c951474b8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 Device: cuda\n",
            "\n",
            "🔍 Evaluating beit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "beit: 100%|██████████| 27/27 [00:26<00:00,  1.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ beit Accuracy: 0.3766\n",
            "\n",
            "🔍 Evaluating convnext\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'module' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-096503b6e874>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_key\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"efficientnet_b0\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mtorch_model_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"efficientnet_b0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_model_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# Set classifier head\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "model_dir = \"/content/saved_models\"\n",
        "\n",
        "# Compress the folder into a zip file\n",
        "shutil.make_archive('saved_models_backup', 'zip', model_dir)\n",
        "\n",
        "# Download the zip file\n",
        "files.download('saved_models_backup.zip')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "O2sRP0I0qVU-",
        "outputId": "5121dc3c-f8d6-41aa-ea15-bd26d1ee5090"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_90ef9830-d072-4f50-aa5e-b81aa63a38b0\", \"saved_models_backup.zip\", 1145914100)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}